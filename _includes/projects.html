<div class="user-details">
  <h1> Featured Projects </h1>
  <!-- <nav>
    <span><a href="#">Home</a></span>
    <span><a href="#">About</a></span>
    <span><a href="#">Contact</a></span>
  </nav> -->
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="autodrive" src="{{ "/assets/img/autodrive.jpeg" | prepend: site.baseurl }}" />
  </div>
  <div class="contents">
    <h3> Autonommous driving using Deep Reinforcement Learning</h3>
    <!-- <ul>
      <li> Featured Skills</li>
    </ul> -->
    <p>Used a canonical actor-critic method - <a target="blank_" href="https://arxiv.org/abs/1509.02971">Deep
        Deterministic Policy
        Gradients</a> to train an agent to follow lanes. The training was done in a simulation environment using the <a
        href="http://carla.org/" target="blank_">Carla Simulator</a>. The work was primarily motivated by <a
        href="https://arxiv.org/pdf/1807.00412.pdf" target="blank_">Kendall et. al</a>. Major changes were done to shape
      the reward
      signal.
      Also, an attempt was made to incorporate the partial observability of the environment by using recurrent neural
      networks.</p>
    <a class="project-link" target="blank_" href="https://github.com/ankur-rc/autodrive_ddpg">code</a><a
      class="project-link" target="blank_"
      href="https://docs.google.com/viewer?url=https://github.com/ankur-rc/autodrive_ddpg/raw/master/rl_project_report.pdf">report</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="dronet_am" src="{{ "/assets/img/dronet_activation_maps.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3> Dronet Activation Maps </h3>
    <!-- <ul>
      <li> Featured Skills</li>
    </ul> -->
    <p>Added support for visualizing the decisions made by the <a target="blank_"
        href="https://github.com/uzh-rpg/rpg_public_dronet">Dronet</a> neural network by publishing activation maps. The
      activation maps signify the regions of an image which contribute most to the decision made the neural network.
      It was based on <a target="blank_" href="https://arxiv.org/abs/1610.02391">Grad-CAM: Visual Explanations from Deep
        Networks via
        Gradient-based Localization</a>. The project was to determine how well Dronet generalises for a ground
      vehicle. The experiments were performed on a Polaris GEM e6.</p>
    <a class="project-link" href="https://github.com/ankur-rc/dronet_activation_maps" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="drivable" src="{{ "/assets/img/drivable_area.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents">
    <h3> Drivable Area <h4>(Ongoing)</h4>
    </h3>
    <p>The aim of this project is to derive a driving policy directly from visual space. Currently, a segmentation
      network has been trained on a subset of the <a href="http://bair.berkeley.edu/blog/2018/05/30/bdd/"
        target="blank_">BDD100K</a> dataset.
      The segmentation network uses a <a href="https://arxiv.org/abs/1602.07360" target="blank_">SqueezeNet</a>
      backbone.
    </p>
    <a class="project-link" href="https://github.com/ankur-rc/drivable_area" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="face_rec" src="{{ "/assets/img/dml.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3> Face-Recognition Module </h3>
    <p> "Face Trigger” (FT) is a framework for building applications that rely on face-recognition. It enables the
      development of an end-to-end pipeline for training a machine learning classifier for the purposes of identifying
      people’s faces. The model was based on a deep neural network inspired from <a
        href="https://arxiv.org/abs/1503.03832" target="blank_">FaceNet</a>.
      The project was implemented as a python package, to be used to develop other applications. As a POC, a real-time
      face recognition application was developed on AWS DeepLens.</p>
    <a class="project-link" href="https://github.com/ankur-rc/facerec_dml" target="blank_">code</a><a
      class="project-link" href="https://ankur-rc.github.io/facerec_dml/site/html/index.html"
      target="blank_">documentation</a><a class="project-link" href="https://github.com/ankur-rc/deeplens_facerec"
      target="blank_">app</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="lstm" src="{{ "/assets/img/lstm.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents">
    <h3> Human Activity Recognition </h3>
    <p>The aim of the project was to develop a machine learning model to recognise human activities: stand, walk, walk
      upstairs, walk downstairs, sit and run.
      Many models were developed including classical methods like SVM and various neural network architectures like CNN,
      LSTM, CNN-LSTM, ConvLSTM. The dataset used was the <a
        href="https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones" target="blank_">UCI
        HAR dataset</a>.
      The trained model was deployed in an Android application.
    </p>
    <a class="project-link" href="https://github.com/ankur-rc/human_activity_recognition" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="fragonfly" src="{{ "/assets/img/dragonfly.webp" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3> Dragonfly ROS node </h3>
    <p>Created a ROS node for straeming sensor data from <a href="https://www.perceptin.io/products" target="blank_">
        Perceptin's
        Dragonfly computer vision module</a>. Dragonfly vision module has 2 stereo pairs (front + back) and an IMU unit,
      all
      of which are hardware synchronized.
    </p>
    <a class="pill project-link" href="https://github.com/ankur-rc/usl_dragonfly" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="path plan" src="{{ "/assets/img/path.jpeg" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-left">
    <h3>UAV Path Planning</h3>
    <p>The aim of the project was to generate a path for a UAV to traverse in order to find a missing person. As input,
      a probability density map was given which indicated the probability of finding the missing person in one of the
      grid locations.
      The path was generated such that the UAV prioritises locations that have a high probability density. A
      meta-heuristic algorithm was applied to generate the path, called Local Hill Climbing.
    </p>
    <a class="project-link" href="https://github.com/ankur-rc/hill-climb_path_gen" target="blank_">code</a>
    <a class="project-link" href="https://www.youtube.com/watch?v=LskhySoaqz4" target="blank_">video</a>
    <a class="project-link"
      href="https://docs.google.com/viewer?url=https://github.com/ankur-rc/hill-climb_path_gen/raw/master/code/927001907_project1/report.pdf"
      target="blank_">report</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="csp" src="{{ "/assets/img/csp.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3>UAV Mission Planning</h3>
    <p>The aim of the project was to assign missions to pilots, respecting certain eligibility criteria.
      As input, 3 lists were provided. The first list included the pilots and the corresponding Aerial vehicles they can
      fly.
      The second list contained UAVs and the mission types they could support along with a quantity of each UAV type.
      The third and final list had bunch of missions along with their types. The mission planner had to assign each
      pilot to a UAV and a corresponding mission.
      All constraints had to be respected. </p>
    <a class="project-link" href="https://github.com/ankur-rc/csp_mission_plan" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="vpc" src="{{ "/assets/img/bp.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents">
    <h3> VPC Indirect Branch Predictor</h3>
    <p> Reproduced the <a href="https://dl.acm.org/citation.cfm?id=1250715" target="blank_"> Virtual Program Counter
      </a> indirect
      branch predictor. VPC treats each indirect branch as multiple virtual conditional branches. As a result of which,
      the existing conditional branch prediction hardware can be used.
      A conditional branch prediction algorithm was also reproduced based on <a
        href="http://www.cs.virginia.edu/~skadron/Papers/taco_bpred_sep05.pdf" targte="blank_">Merging Path and GShare
        Indexing
        Perceptron</a> branch prediction.</a>
    </p>
    <a class="project-link" href="https://github.com/ankur-rc/VPC-Indirect-Branch-Predictor" target="blank_">code</a>
    <a class="project-link"
      href="https://docs.google.com/viewer?url=https://github.com/ankur-rc/VPC-Indirect-Branch-Predictor/raw/master/report/Project%20Report.pdf"
      target="blank_">report</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="cache" src="{{ "/assets/img/cache.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3>Cache Reuse Predictor</h3>
    <p>A cache reuse and bypass predictor for LLC using the perceptron learning algorithm. Based on <a
        href="http://hpca23.cse.tamu.edu/pdfs/micro2016-perceptron.pdf" target="blank_">Teran et al., MICRO
        2016</a>.</p>
    <a class="project-link" href="https://github.com/ankur-rc/Perceptron-learning-Cache-Reuse-Predictor"
      target="blank_">code</a>
    <a class="project-link"
      href="https://docs.google.com/viewer?url=https://github.com/ankur-rc/Perceptron-learning-Cache-Reuse-Predictor/raw/master/report.pdf"
      target="blank_">report</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="blyton" src="{{ "/assets/img/blyton.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents">
    <h3>Blyton - Recommender System</h3>
    <p>Blyton is a unique book recommender system to generate recommendations for readers based on their guided reading
      levels.
    </p>
    <a class="project-link" href="https://github.com/ankur-rc/blyton-book_recommender" target="blank_">code</a>
    <a class="project-link" href="https://ankur-rc.github.io/blyton-book_recommender/" target="blank_">documentation</a>
    <a class="project-link" href="https://drive.google.com/open?id=1p0c06MfDv0IfNJjIirwQxibP-XFDfsyL"
      target="blank_">video</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="dronet_carla" src="{{ "/assets/img/dronet_carla.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3>Dronet on CoRL benchmark</h3>
    <p>The project aimed to benchmark <a href="https://github.com/uzh-rpg/rpg_public_dronet"
        target="blank_">Dronet's</a> performance on <a href="http://carla.org/" target="blank_">Carla's</a> CoRL 2017
      benchmark suite. Dronet is a neural network that takes as input monocular images and provides 2 outputs:
      probability of collision aand steering angle.
      Unfortunately, the pre-trained network did not perform well as it was trained on real-life images. The network
      needs to be trained on synthetic images or some form of domain adaptation needs to be applied.</p>
    <a class="project-link" href="https://github.com/ankur-rc/dronet_carla" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="yaw" src="{{ "/assets/img/yaw.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents">
    <h3> Yaw prediction from sensors </h3>
    <p>The project was to predict the yaw angles from raw sensor readings from an IMU. The aim of the project was to
      reverse engineer the Kalman filters used in expensive IMUs, so that a function could be learnt from sensor
      readings to orientation.
      The data was collected on a VectorNav IMU (VN-200) and a cheaper PixHawk IMU. The function approximator used was a
      recurrent neural network.
    </p>
    <a class="project-link" href="https://github.com/ankur-rc/raw_2_yaw" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="cc" src="{{ "/assets/img/career_closet.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3>Career Closet - Webapp</h3>
    <p>TAMU Career Closet is an inventory management system built on Ruby on Rails and Angular 2. It helps
      administrators at <a href="An inventory management webapp built on Ruby on Rails and Angular 2. https://tamu-career-closet-client.her…
https://careercloset.tamu.edu/" target="blank_">TAMU Career Closet</a> manage their inventory. For accessing the demo
      please enter the following credentials:
      <ul>
        <li>Username: ankurrc@gmail.com</li>
        <li>Password: ankur@123</li>
      </ul>
    </p>
    <a class="project-link" href="https://github.com/ankur-rc/tamu_career_closet" target="blank_">code</a>
    <a class="project-link" href="https://tamu-career-closet-client.herokuapp.com" target="blank_">demo</a>
  </div>
</div>