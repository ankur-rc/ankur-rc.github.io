<div class="user-details">
  <h1> Featured Projects </h1>
  <!-- <nav>
    <span><a href="#">Home</a></span>
    <span><a href="#">About</a></span>
    <span><a href="#">Contact</a></span>
  </nav> -->
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="autodrive" src="{{ "/assets/img/autodrive.jpeg" | prepend: site.baseurl }}" />
  </div>
  <div class="contents">
    <h3> Autonommous driving using Deep Reinforcement Learning</h3>
    <!-- <ul>
      <li> Featured Skills</li>
    </ul> -->
    <p>Used a canonical actor-critic method - <a target="blank_" href="https://arxiv.org/abs/1509.02971">Deep
        Deterministic Policy
        Gradients</a> to train an agent to follow lanes. The training was done in a simulation environment using the <a
        href="http://carla.org/" target="blank_">Carla Simulator</a>. The work was primarily motivated by <a
        href="https://arxiv.org/pdf/1807.00412.pdf" target="blank_">Kendall et. al</a>. Major changes were done to shape
      the reward
      signal.
      Also, an attempt was made to incorporate the partial observability of the environment by using recurrent neural
      networks.</p>
    <a class="project-link" target="blank_" href="https://github.com/ankur-rc/autodrive_ddpg">code</a><a
      class="project-link" target="blank_"
      href="https://docs.google.com/viewer?url=https://github.com/ankur-rc/autodrive_ddpg/raw/master/rl_project_report.pdf">report</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="dronet_am" src="{{ "/assets/img/dronet_activation_maps.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3> Dronet Activation Maps </h3>
    <!-- <ul>
      <li> Featured Skills</li>
    </ul> -->
    <p>Added support for visualizing the decisions made by the <a target="blank_"
        href="https://github.com/uzh-rpg/rpg_public_dronet">Dronet</a> neural network by publishing activation maps. The
      activation maps signify the regions of an image which contribute most to the decision made the neural network.
      It was based on <a target="blank_" href="https://arxiv.org/abs/1610.02391">Grad-CAM: Visual Explanations from Deep
        Networks via
        Gradient-based Localization</a>. The project was to determine how well Dronet generalises for a ground
      vehicle. The experiments were performed on a Polaris GEM e6.</p>
    <a class="project-link" href="https://github.com/ankur-rc/dronet_activation_maps" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="drivable" src="{{ "/assets/img/drivable_area.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents">
    <h3> Drivable Area <h4>(Ongoing)</h4>
    </h3>
    <p>The aim of this project is to derive a driving policy directly from visual space. Currently, a segmentation
      network has been trained on a subset of the <a href="http://bair.berkeley.edu/blog/2018/05/30/bdd/"
        target="blank_">BDD100K</a> dataset.
      The segmentation network uses a <a href="https://arxiv.org/abs/1602.07360" target="blank_">SqueezeNet</a>
      backbone.
    </p>
    <a class="project-link" href="https://github.com/ankur-rc/drivable_area" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="face_rec" src="{{ "/assets/img/dml.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3> Face-Recognition Module </h3>
    <p> "Face Trigger” (FT) is a framework for building applications that rely on face-recognition. It enables the
      development of an end-to-end pipeline for training a machine learning classifier for the purposes of identifying
      people’s faces. The model was based on a deep neural network inspired from <a
        href="https://arxiv.org/abs/1503.03832" target="blank_">FaceNet</a>.
      The project was implemented as a python package, to be used to develop other applications. As a POC, a real-time
      face recognition application was developed on AWS DeepLens.</p>
    <a class="project-link" href="https://github.com/ankur-rc/facerec_dml" target="blank_">code</a><a
      class="project-link" href="https://ankur-rc.github.io/facerec_dml/site/html/index.html"
      target="blank_">documentation</a><a class="project-link" href="https://github.com/ankur-rc/deeplens_facerec"
      target="blank_">app</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="yaw" src="{{ "/assets/img/yaw.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents">
    <h3> Yaw prediction from sensors </h3>
    <p>The project was to predict the yaw angles from raw sensor readings from an IMU. The aim of the project was to
      reverse engineer the Kalman filters used in expensive IMUs, so that a function could be learnt from sensor
      readings to orientation.
      The data was collected on a VectorNav IMU (VN-200) and a cheaper PixHawk IMU. The function approximator used was a
      recurrent neural network.
    </p>
    <a class="pill project-link" href="https://github.com/ankur-rc/raw_2_yaw" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="dronet_carla" src="{{ "/assets/img/dronet_carla.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3> Carla benchmark on Dronet </h3>
    <p>The project aimed to benchmark <a href="https://github.com/uzh-rpg/rpg_public_dronet"
        target="blank_">Dronet's</a> performance on <a href="http://carla.org/" target="blank_">Carla's</a> CoRL 2017
      benchmark suite. Dronet is a neural network that takes as input monocular images and provides 2 outputs:
      probability of collision aand steering angle.
      Unfortunately, the pre-trained network did not perform well as it was trained on real-life images. The network
      needs to be trained on synthetic images or some form of domain adaptation needs to be applied.</p>
    <a class="project-link" href="https://github.com/ankur-rc/dronet_carla" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-right">
    <img alt="yaw" src="{{ "/assets/img/yaw.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents">
    <h3> Yaw prediction from sensors </h3>
    <p>The project was to predict the yaw angles from raw sensor readings from an IMU. The aim of the project was to
      reverse engineer the Kalman filters used in expensive IMUs, so that a function could be learnt from sensor
      readings to orientation.
      The data was collected on a VectorNav IMU (VN-200) and a cheaper PixHawk IMU. The function approximator used was a
      recurrent neural network.
    </p>
    <a class="pill project-link" href="https://github.com/ankur-rc/raw_2_yaw" target="blank_">code</a>
  </div>
</div>
<div class="user-projects">
  <div class="images-left">
    <img alt="dronet_carla" src="{{ "/assets/img/dronet_carla.png" | prepend: site.baseurl }}" />
  </div>
  <div class="contents-right">
    <h3> Carla benchmark on Dronet </h3>
    <p>The project aimed to benchmark <a href="https://github.com/uzh-rpg/rpg_public_dronet"
        target="blank_">Dronet's</a> performance on <a href="http://carla.org/" target="blank_">Carla's</a> CoRL 2017
      benchmark suite. Dronet is a neural network that takes as input monocular images and provides 2 outputs:
      probability of collision aand steering angle.
      Unfortunately, the pre-trained network did not perform well as it was trained on real-life images. The network
      needs to be trained on synthetic images or some form of domain adaptation needs to be applied.</p>
    <a class="project-link" href="https://github.com/ankur-rc/dronet_carla" target="blank_">code</a>
  </div>
</div>